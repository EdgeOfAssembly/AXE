# Provider Infrastructure Configuration
# This file defines provider connection details and available models.
# Loaded SECOND in the config chain: models.yaml → providers.yaml → axe.yaml

providers:
  # ===========================================================================
  # Anthropic Claude API
  # ===========================================================================
  anthropic:
    enabled: true
    env_key: ANTHROPIC_API_KEY
    base_url: null  # Uses default Anthropic API endpoint
    models:
      - claude-opus-4-5-20251101
      - claude-sonnet-4-5-20250929
      - claude-haiku-4-5-20251001
      - claude-opus-4-1-20250805
      - claude-opus-4-20250514
      - claude-sonnet-4-20250514
      - claude-3-5-haiku-20241022
      - claude-3-haiku-20240307

  # ===========================================================================
  # OpenAI GPT API (direct)
  # ===========================================================================
  openai:
    enabled: true
    env_key: OPENAI_API_KEY
    base_url: null  # Uses default OpenAI API endpoint
    models:
      - gpt-5.2-2025-12-11
      - gpt-5.2
      - gpt-5.2-pro
      - gpt-4.1
      - gpt-4.1-mini
      - gpt-4o
      - gpt-4o-mini
      - gpt-4-turbo
      - o3
      - o3-mini
      - o4-mini

  # ===========================================================================
  # xAI Grok API
  # ===========================================================================
  xai:
    enabled: true
    env_key: XAI_API_KEY
    base_url: https://api.x.ai/v1
    models:
      - grok-4-1-fast-reasoning
      - grok-4-fast-reasoning
      - grok-code-fast-1
      - grok-2-vision-1212
      - grok-2-image-1212

  # ===========================================================================
  # HuggingFace Inference API
  # ===========================================================================
  huggingface:
    enabled: true
    env_key: HUGGINGFACE_API_KEY
    base_url: null  # Uses default HuggingFace endpoint
    models:
      - meta-llama/Llama-3.3-70B-Instruct
      - meta-llama/Llama-3.1-70B-Instruct
      - meta-llama/llama-3.1-70b-instruct  # Lowercase variant
      - meta-llama/Llama-3.1-8B-Instruct

  # ===========================================================================
  # GitHub Models API
  # Note: Model IDs include provider prefix by design (openai/, meta/, etc.)
  # ===========================================================================
  github:
    enabled: true
    env_key: GITHUB_TOKEN
    base_url: https://models.github.ai/inference
    models:
      # OpenAI GPT-4 series
      - openai/gpt-4o
      - openai/gpt-4o-mini
      - openai/gpt-4.1
      - openai/gpt-4.1-mini
      - openai/gpt-4.1-nano
      # OpenAI GPT-5 series
      - openai/gpt-5
      - openai/gpt-5-chat
      - openai/gpt-5-mini
      - openai/gpt-5-nano
      # OpenAI o-series (reasoning)
      - openai/o1
      - openai/o1-mini
      - openai/o1-preview
      - openai/o3
      - openai/o3-mini
      - openai/o4-mini
      # Meta Llama series
      - meta/llama-4-scout-17b-16e-instruct
      - meta/llama-4-maverick-17b-128e-instruct-fp8
      - meta/llama-3.2-90b-vision-instruct
      - meta/llama-3.2-11b-vision-instruct
      - meta/llama-3.3-70b-instruct
      - meta/meta-llama-3.1-405b-instruct
      - meta/meta-llama-3.1-8b-instruct
      # Mistral AI series
      - mistral-ai/codestral-2501
      - mistral-ai/ministral-3b
      - mistral-ai/mistral-medium-2505
      - mistral-ai/mistral-small-2503
      # DeepSeek series
      - deepseek/deepseek-r1
      - deepseek/deepseek-r1-0528
      - deepseek/deepseek-v3-0324
      # Microsoft Phi series
      - microsoft/phi-4
      - microsoft/phi-4-mini-instruct
      - microsoft/phi-4-mini-reasoning
      - microsoft/phi-4-multimodal-instruct
      - microsoft/phi-4-reasoning
      - microsoft/mai-ds-r1
      # Cohere series
      - cohere/cohere-command-a
      - cohere/cohere-command-r-08-2024
      - cohere/cohere-command-r-plus-08-2024
      # AI21 Labs
      - ai21-labs/ai21-jamba-1.5-large
      # xAI Grok
      - xai/grok-3
      - xai/grok-3-mini
      # OpenAI Embeddings
      - openai/text-embedding-3-large
      - openai/text-embedding-3-small

  # ===========================================================================
  # Dashscope/Qwen API (Alibaba Cloud)
  # ===========================================================================
  dashscope:
    enabled: true
    env_key: DASHSCOPE_API_KEY
    base_url: https://dashscope-intl.aliyuncs.com/compatible-mode/v1
    models:
      - Qwen/Qwen3-VL-235B-A22B-Thinking-25700
      - qwen/qwen3-vl-235b-a22b-thinking-25700  # Lowercase variant
      - Qwen/Qwen3-Coder-480B-A35B-Instruct
      - qwen/qwen3-coder-480b-a35b-instruct  # Lowercase variant
      - Qwen/Qwen3-VL-235B-A22B-Thinking
      - qwen/qwen3-vl-235b-a22b-thinking  # Lowercase variant
      - Qwen/Qwen-Image
      - Qwen/Qwen-Image-Edit-2511

  # ===========================================================================
  # DeepSeek API (direct)
  # ===========================================================================
  deepseek:
    enabled: true
    env_key: DEEPSEEK_API_KEY
    base_url: https://api.deepseek.com/v1
    models:
      - deepseek-ai/DeepSeek-V3.2
      - deepseek-ai/deepseek-v3.2  # Lowercase variant

  # ===========================================================================
  # Ollama (Local LLM Server)
  # Disabled by default - enable when you have Ollama running locally
  # Installation: https://ollama.ai/
  # ===========================================================================
  ollama:
    enabled: false  # Enable when Ollama is installed and running
    env_key: OLLAMA_API_KEY  # Placeholder - Ollama doesn't require auth by default
    base_url: http://localhost:11434/v1
    models:
      - llama3.1:70b
      - llama3.1:8b
      - codellama:34b
      - deepseek-coder:33b
      - mistral:7b
      - mixtral:8x7b
