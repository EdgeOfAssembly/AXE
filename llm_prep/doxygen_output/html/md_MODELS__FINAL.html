<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.15.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AXE: AXE Multi-Agent System - Model Configuration Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">AXE
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.15.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('md_MODELS__FINAL.html','',''); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">AXE Multi-Agent System - Model Configuration Reference </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md613"></a></p>
<blockquote class="doxtable">
<p><b>Version</b>: 1.0 <br  />
 <b>Last Updated</b>: December 2025 <br  />
 </p>
</blockquote>
<hr  />
<h1 class="doxsection"><a class="anchor" id="autotoc_md615"></a>
Table of Contents</h1>
<ol type="1">
<li>Quick Start</li>
<li>Anthropic (Claude)</li>
<li>HuggingFace (Llama)</li>
<li>OpenAI (GPT)</li>
<li>xAI (Grok)</li>
<li>GitHub Models</li>
<li>Model Capabilities Matrix</li>
<li>Usage Examples</li>
</ol>
<hr  />
<h1 class="doxsection"><a class="anchor" id="autotoc_md617"></a>
Quick Start</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md618"></a>
Environment Setup</h2>
<div class="fragment"><div class="line"># Load all API keys at once</div>
<div class="line">source /path/to/models_env.sh</div>
<div class="line"> </div>
<div class="line"># Or set individually</div>
<div class="line">export ANTHROPIC_API_KEY=&#39;your-key&#39;</div>
<div class="line">export HUGGINGFACE_API_KEY=&#39;your-key&#39;</div>
<div class="line">export OPENAI_API_KEY=&#39;your-key&#39;</div>
<div class="line">export XAI_API_KEY=&#39;your-key&#39;</div>
<div class="line">export GITHUB_TOKEN=&#39;your-key&#39;</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md619"></a>
Test Connection</h2>
<div class="fragment"><div class="line"><span class="keyword">from</span> axe <span class="keyword">import</span> test_model_connection</div>
<div class="line">test_model_connection(<span class="stringliteral">&quot;llama&quot;</span>)  <span class="comment"># Test HuggingFace Llama</span></div>
<div class="line">test_model_connection(<span class="stringliteral">&quot;claude&quot;</span>) <span class="comment"># Test Anthropic Claude</span></div>
</div><!-- fragment --><hr  />
<h1 class="doxsection"><a class="anchor" id="autotoc_md621"></a>
Anthropic (Claude)</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md622"></a>
Configuration</h2>
<div class="fragment"><div class="line">export ANTHROPIC_API_KEY=&#39;sk-ant-api03-...&#39;</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md623"></a>
Latest Models</h2>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Model  </th><th class="markdownTableHeadNone">Type  </th><th class="markdownTableHeadNone">Context  </th><th class="markdownTableHeadNone">Best For  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><span class="tt">claude-opus-4-5</span>  </td><td class="markdownTableBodyNone">General  </td><td class="markdownTableBodyNone">200K tokens  </td><td class="markdownTableBodyNone">Complex reasoning, coding, analysis  </td></tr>
</table>
<h2 class="doxsection"><a class="anchor" id="autotoc_md624"></a>
Usage</h2>
<div class="fragment"><div class="line"><span class="keyword">from</span> anthropic <span class="keyword">import</span> Anthropic</div>
<div class="line"> </div>
<div class="line">client = Anthropic(api_key=os.environ[<span class="stringliteral">&quot;ANTHROPIC_API_KEY&quot;</span>])</div>
<div class="line"> </div>
<div class="line">response = client.messages.create(</div>
<div class="line">    model=<span class="stringliteral">&quot;claude-opus-4-5&quot;</span>,</div>
<div class="line">    max_tokens=4096,</div>
<div class="line">    messages=[{<span class="stringliteral">&quot;role&quot;</span>: <span class="stringliteral">&quot;user&quot;</span>, <span class="stringliteral">&quot;content&quot;</span>: <span class="stringliteral">&quot;Your prompt&quot;</span>}]</div>
<div class="line">)</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md625"></a>
Notes</h2>
<ul>
<li>Highest quality reasoning</li>
<li>Best for supervisor/coordinator roles</li>
<li>Credit-based billing</li>
</ul>
<hr  />
<h1 class="doxsection"><a class="anchor" id="autotoc_md627"></a>
HuggingFace (Llama)</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md628"></a>
Configuration</h2>
<div class="fragment"><div class="line">export HUGGINGFACE_API_KEY=&quot;hf_...&quot;</div>
<div class="line"> </div>
<div class="line"># Or using HuggingFace CLI</div>
<div class="line">hf auth login</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md629"></a>
Latest Models</h2>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Model  </th><th class="markdownTableHeadNone">Type  </th><th class="markdownTableHeadNone">Context  </th><th class="markdownTableHeadNone">Best For  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><span class="tt">meta-llama/Llama-4-Maverick-17B-128E-Instruct</span>  </td><td class="markdownTableBodyNone">General/Coding/Vision  </td><td class="markdownTableBodyNone">Large  </td><td class="markdownTableBodyNone">Multi-modal tasks  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><span class="tt">meta-llama/Llama-3.1-405B-Instruct</span>  </td><td class="markdownTableBodyNone">General/Coding  </td><td class="markdownTableBodyNone">Large  </td><td class="markdownTableBodyNone">High-quality reasoning  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><span class="tt">meta-llama/Llama-4-Scout-17B-16E-Instruct</span>  </td><td class="markdownTableBodyNone">Vision  </td><td class="markdownTableBodyNone">Large  </td><td class="markdownTableBodyNone">Image understanding  </td></tr>
</table>
<h2 class="doxsection"><a class="anchor" id="autotoc_md630"></a>
Usage - OpenAI-Compatible API</h2>
<div class="fragment"><div class="line"><span class="keyword">import</span> os</div>
<div class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</div>
<div class="line"> </div>
<div class="line">client = OpenAI(</div>
<div class="line">    base_url=<span class="stringliteral">&quot;https://router.huggingface.co/v1&quot;</span>,</div>
<div class="line">    api_key=os.environ[<span class="stringliteral">&quot;HUGGINGFACE_API_KEY&quot;</span>],</div>
<div class="line">)</div>
<div class="line"> </div>
<div class="line">completion = client.chat.completions.create(</div>
<div class="line">    model=<span class="stringliteral">&quot;meta-llama/Llama-3.1-405B-Instruct:sambanova&quot;</span>,</div>
<div class="line">    messages=[</div>
<div class="line">        {<span class="stringliteral">&quot;role&quot;</span>: <span class="stringliteral">&quot;user&quot;</span>, <span class="stringliteral">&quot;content&quot;</span>: <span class="stringliteral">&quot;What is the capital of France?&quot;</span>}</div>
<div class="line">    ],</div>
<div class="line">)</div>
<div class="line">print(completion.choices[0].message)</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md631"></a>
Usage - Transformers (Local)</h2>
<div class="fragment"><div class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoProcessor, AutoModelForMultimodalLM</div>
<div class="line"> </div>
<div class="line">processor = AutoProcessor.from_pretrained(</div>
<div class="line">    <span class="stringliteral">&quot;meta-llama/Llama-4-Scout-17B-16E-Instruct&quot;</span></div>
<div class="line">)</div>
<div class="line">model = AutoModelForMultimodalLM.from_pretrained(</div>
<div class="line">    <span class="stringliteral">&quot;meta-llama/Llama-4-Scout-17B-16E-Instruct&quot;</span></div>
<div class="line">)</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md632"></a>
Notes</h2>
<ul>
<li><b>WORKING</b> - Verified with HuggingFace Inference API</li>
<li>Good for worker agents</li>
<li>Free tier available with quotas</li>
</ul>
<hr  />
<h1 class="doxsection"><a class="anchor" id="autotoc_md634"></a>
OpenAI (GPT)</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md635"></a>
Configuration</h2>
<div class="fragment"><div class="line">export OPENAI_API_KEY=&quot;sk-proj-...&quot;</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md636"></a>
Latest Models</h2>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Model  </th><th class="markdownTableHeadNone">Type  </th><th class="markdownTableHeadNone">Context  </th><th class="markdownTableHeadNone">Best For  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><span class="tt">gpt-5.2-2025-12-11</span>  </td><td class="markdownTableBodyNone">General  </td><td class="markdownTableBodyNone">Large  </td><td class="markdownTableBodyNone">Latest capabilities  </td></tr>
</table>
<h2 class="doxsection"><a class="anchor" id="autotoc_md637"></a>
Usage</h2>
<div class="fragment"><div class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</div>
<div class="line"> </div>
<div class="line">client = OpenAI(api_key=os.environ[<span class="stringliteral">&quot;OPENAI_API_KEY&quot;</span>])</div>
<div class="line"> </div>
<div class="line">response = client.chat.completions.create(</div>
<div class="line">    model=<span class="stringliteral">&quot;gpt-5.2-2025-12-11&quot;</span>,</div>
<div class="line">    messages=[{<span class="stringliteral">&quot;role&quot;</span>: <span class="stringliteral">&quot;user&quot;</span>, <span class="stringliteral">&quot;content&quot;</span>: <span class="stringliteral">&quot;Your prompt&quot;</span>}]</div>
<div class="line">)</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md638"></a>
Notes</h2>
<ul>
<li>Credit-based billing</li>
<li>Extensive function calling support</li>
</ul>
<hr  />
<h1 class="doxsection"><a class="anchor" id="autotoc_md640"></a>
xAI (Grok)</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md641"></a>
Configuration</h2>
<div class="fragment"><div class="line">export XAI_API_KEY=&quot;xai-...&quot;</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md642"></a>
Latest Models</h2>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Model  </th><th class="markdownTableHeadNone">Input  </th><th class="markdownTableHeadNone">Output  </th><th class="markdownTableHeadNone">Context  </th><th class="markdownTableHeadNone">Rate Limit  </th><th class="markdownTableHeadNone">Capabilities  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><span class="tt">grok-4-1-fast</span>  </td><td class="markdownTableBodyNone">Text  </td><td class="markdownTableBodyNone">Text  </td><td class="markdownTableBodyNone">2M tokens  </td><td class="markdownTableBodyNone">4M tokens/min  </td><td class="markdownTableBodyNone">Function calling, structured outputs  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><span class="tt">grok-code-fast</span>  </td><td class="markdownTableBodyNone">Text  </td><td class="markdownTableBodyNone">Text  </td><td class="markdownTableBodyNone">256K tokens  </td><td class="markdownTableBodyNone">2M tokens/min  </td><td class="markdownTableBodyNone">Function calling, structured outputs  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><span class="tt">grok-2-vision</span>  </td><td class="markdownTableBodyNone">Image+Text  </td><td class="markdownTableBodyNone">Text  </td><td class="markdownTableBodyNone">32K tokens  </td><td class="markdownTableBodyNone">-  </td><td class="markdownTableBodyNone">Function calling, structured outputs  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><span class="tt">grok-2-image</span>  </td><td class="markdownTableBodyNone">Text  </td><td class="markdownTableBodyNone">Image  </td><td class="markdownTableBodyNone">-  </td><td class="markdownTableBodyNone">-  </td><td class="markdownTableBodyNone">Image generation  </td></tr>
</table>
<h2 class="doxsection"><a class="anchor" id="autotoc_md643"></a>
Usage - Text Generation</h2>
<div class="fragment"><div class="line"><span class="keyword">from</span> xai_sdk <span class="keyword">import</span> Client</div>
<div class="line"> </div>
<div class="line">client = Client(api_key=os.environ[<span class="stringliteral">&quot;XAI_API_KEY&quot;</span>])</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Text completion</span></div>
<div class="line">response = client.chat.completions.create(</div>
<div class="line">    model=<span class="stringliteral">&quot;grok-4-1-fast&quot;</span>,</div>
<div class="line">    messages=[{<span class="stringliteral">&quot;role&quot;</span>: <span class="stringliteral">&quot;user&quot;</span>, <span class="stringliteral">&quot;content&quot;</span>: <span class="stringliteral">&quot;Your prompt&quot;</span>}]</div>
<div class="line">)</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md644"></a>
Usage - Image Generation</h2>
<div class="fragment"><div class="line"><span class="keyword">from</span> xai_sdk <span class="keyword">import</span> Client</div>
<div class="line"> </div>
<div class="line">client = Client(api_key=os.environ[<span class="stringliteral">&quot;XAI_API_KEY&quot;</span>])</div>
<div class="line"> </div>
<div class="line">response = client.image.sample(</div>
<div class="line">    model=<span class="stringliteral">&quot;grok-2-image&quot;</span>,</div>
<div class="line">    prompt=<span class="stringliteral">&quot;A cat in a tree&quot;</span>,</div>
<div class="line">    image_format=<span class="stringliteral">&quot;url&quot;</span></div>
<div class="line">)</div>
<div class="line">print(response.url)</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md645"></a>
Notes</h2>
<ul>
<li>Very generous rate limits</li>
<li>Good for high-throughput tasks</li>
<li>Premium+ tier recommended</li>
<li>Docs: <a href="https://docs.x.ai/docs/models">https://docs.x.ai/docs/models</a></li>
</ul>
<hr  />
<h1 class="doxsection"><a class="anchor" id="autotoc_md647"></a>
GitHub Models</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md648"></a>
Configuration</h2>
<div class="fragment"><div class="line">export GITHUB_TOKEN=&quot;github_pat_...&quot;</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md649"></a>
Available Models</h2>
<p>Same top models as Anthropic and OpenAI are available through GitHub Copilot:</p><ul>
<li><span class="tt">claude-opus-4-5</span> (Anthropic)</li>
<li><span class="tt">gpt-5.1</span> (OpenAI)</li>
</ul>
<h2 class="doxsection"><a class="anchor" id="autotoc_md650"></a>
Usage</h2>
<div class="fragment"><div class="line"><span class="comment"># Via GitHub Copilot API (enterprise)</span></div>
<div class="line"><span class="comment"># Configuration depends on your GitHub setup</span></div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md651"></a>
Notes</h2>
<ul>
<li><b>WORKING</b> - Verified with GitHub Copilot models</li>
<li>Requires GitHub Copilot subscription</li>
<li>Per-seat or usage-based billing</li>
</ul>
<hr  />
<h1 class="doxsection"><a class="anchor" id="autotoc_md653"></a>
Model Capabilities Matrix</h1>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Provider  </th><th class="markdownTableHeadNone">Model  </th><th class="markdownTableHeadNone">Text  </th><th class="markdownTableHeadNone">Vision  </th><th class="markdownTableHeadNone">Code  </th><th class="markdownTableHeadNone">Function Calling  </th><th class="markdownTableHeadNone">Context  </th><th class="markdownTableHeadNone">Status  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Anthropic  </td><td class="markdownTableBodyNone">claude-opus-4-5  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">200K  </td><td class="markdownTableBodyNone">üî¥ No credits  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">HuggingFace  </td><td class="markdownTableBodyNone">Llama-4-Maverick-17B  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">Large  </td><td class="markdownTableBodyNone">‚úÖ Working  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">HuggingFace  </td><td class="markdownTableBodyNone">Llama-3.1-405B  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚ùå  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">Large  </td><td class="markdownTableBodyNone">‚úÖ Working  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">OpenAI  </td><td class="markdownTableBodyNone">gpt-5.2  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">Large  </td><td class="markdownTableBodyNone">üî¥ No credits  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">xAI  </td><td class="markdownTableBodyNone">grok-4-1-fast  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚ùå  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">2M  </td><td class="markdownTableBodyNone">üî¥ No credits  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">xAI  </td><td class="markdownTableBodyNone">grok-code-fast  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚ùå  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">256K  </td><td class="markdownTableBodyNone">üî¥ No credits  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">xAI  </td><td class="markdownTableBodyNone">grok-2-vision  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">32K  </td><td class="markdownTableBodyNone">üî¥ No credits  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">GitHub  </td><td class="markdownTableBodyNone">claude-opus-4-5  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">200K  </td><td class="markdownTableBodyNone">‚úÖ Working  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">GitHub  </td><td class="markdownTableBodyNone">gpt-5.1  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">‚úÖ  </td><td class="markdownTableBodyNone">Large  </td><td class="markdownTableBodyNone">‚úÖ Working  </td></tr>
</table>
<hr  />
<h1 class="doxsection"><a class="anchor" id="autotoc_md655"></a>
Usage Examples</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md656"></a>
Multi-Agent Collaboration</h2>
<div class="fragment"><div class="line"># Start a collaboration session with multiple models</div>
<div class="line">python3 axe.py \</div>
<div class="line">    --collab llama,grok \</div>
<div class="line">    --workspace ../playground \</div>
<div class="line">    --time 30 \</div>
<div class="line">    --task &quot;Analyze the wadextract code in doom/wadextract&quot;</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md657"></a>
Model Communication Example</h2>
<div class="fragment"><div class="line">@llama1: I found an issue in the sprite rendering code. @grok2, can you verify?</div>
<div class="line">@grok2: Checking now... confirmed. The HERETIC sprite enum values are offset.</div>
<div class="line">@boss: Good catch team. @llama1 please fix and @grok2 write tests.</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md658"></a>
Test Projects for Multi-Agent Work</h2>
<ul>
<li><span class="tt">doom/wadextract</span> - WAD file extraction utilities</li>
<li><span class="tt">doom/dmspec16.txt</span> - DOOM specifications document</li>
<li><span class="tt">ChaosForgeHash</span> - Hash utilities</li>
<li><span class="tt">brain3d_v2</span> - 3D brain visualization</li>
</ul>
<h2 class="doxsection"><a class="anchor" id="autotoc_md659"></a>
Supervisor Role Assignment</h2>
<div class="fragment"><div class="line"># The model that starts axe.py becomes @boss</div>
<div class="line">python3 axe.py --task &quot;Your task&quot;</div>
<div class="line"># This model is now @boss, workers will be @llama1, @grok1, etc.</div>
</div><!-- fragment --><hr  />
<h1 class="doxsection"><a class="anchor" id="autotoc_md661"></a>
Troubleshooting</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md662"></a>
No Credits Error</h2>
<p>If you see "no credits" errors for Anthropic, OpenAI, or Grok:</p><ul>
<li>Use HuggingFace Llama models (free tier available)</li>
<li>Use GitHub Copilot models (included with subscription)</li>
</ul>
<h2 class="doxsection"><a class="anchor" id="autotoc_md663"></a>
Rate Limiting</h2>
<div class="fragment"><div class="line"><span class="keyword">import</span> time</div>
<div class="line"> </div>
<div class="line"><span class="keyword">def </span>call_with_retry(func, *args, max_retries=3, **kwargs):</div>
<div class="line">    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(max_retries):</div>
<div class="line">        <span class="keywordflow">try</span>:</div>
<div class="line">            <span class="keywordflow">return</span> func(*args, **kwargs)</div>
<div class="line">        <span class="keywordflow">except</span> RateLimitError:</div>
<div class="line">            time.sleep(2 ** i)  <span class="comment"># Exponential backoff</span></div>
<div class="line">    <span class="keywordflow">raise</span> Exception(<span class="stringliteral">&quot;Max retries exceeded&quot;</span>)</div>
</div><!-- fragment --><hr  />
 </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<div id="page-nav" class="page-nav-panel">
<div id="page-nav-resize-handle"></div>
<div id="page-nav-tree">
<div id="page-nav-contents">
</div><!-- page-nav-contents -->
</div><!-- page-nav-tree -->
</div><!-- page-nav -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.15.0 </li>
  </ul>
</div>
</body>
</html>
