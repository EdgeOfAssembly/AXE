<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.15.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AXE: Anthropic Claude-Specific Features in AXE</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">AXE
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.15.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('md_docs_2ANTHROPIC__FEATURES.html','',''); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Anthropic Claude-Specific Features in AXE </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md243"></a></p>
<p>This document describes the Anthropic Claude-specific optimizations implemented in AXE to enable handling large codebases more efficiently with minimal token count and cost.</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md244"></a>
Overview</h1>
<p>AXE now includes four major Anthropic-specific features:</p>
<ol type="1">
<li><b>Prompt Caching</b> (Highest Priority) - Significantly reduces processing time and costs for repetitive tasks</li>
<li><b>Extended Thinking</b> - Enhanced reasoning capabilities for complex tasks</li>
<li><b>Token Counting</b> - Precise token counts from Anthropic API</li>
<li><b>Files API</b> (Beta) - Upload large files once, reference multiple times</li>
</ol>
<p>All features are <b>opt-in</b> and maintain <b>full backward compatibility</b> with other providers (OpenAI, xAI, HuggingFace, GitHub).</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md245"></a>
Features</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md246"></a>
1. Prompt Caching</h2>
<p>Prompt caching reduces costs by reusing previously processed content. The cache has a 5-minute lifetime by default and is automatically refreshed when used.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md247"></a>
Configuration</h3>
<p>In <span class="tt">models.yaml</span>:</p>
<div class="fragment"><div class="line">anthropic:</div>
<div class="line">  prompt_caching:</div>
<div class="line">    enabled: true                              # Enable prompt caching</div>
<div class="line">    cache_breakpoints: [&quot;system&quot;, &quot;tools&quot;]     # What to cache</div>
<div class="line">    default_ttl: &quot;5m&quot;                          # Cache lifetime: &quot;5m&quot; or &quot;1h&quot;</div>
</div><!-- fragment --><h3 class="doxsection"><a class="anchor" id="autotoc_md248"></a>
How It Works</h3>
<ul>
<li>Static content (system prompts, tool definitions) is automatically cached</li>
<li>Cache is created on first use (costs normal rate)</li>
<li>Subsequent uses read from cache (90% cost reduction)</li>
<li>Cache refreshes automatically when accessed within TTL</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md249"></a>
Token Savings Example</h3>
<div class="fragment"><div class="line">First call:  10,000 input tokens → Normal cost</div>
<div class="line">Second call: 9,500 cached + 500 new → ~90% savings</div>
<div class="line">Third call:  9,500 cached + 500 new → ~90% savings</div>
</div><!-- fragment --><h3 class="doxsection"><a class="anchor" id="autotoc_md250"></a>
Automatic Features</h3>
<ul>
<li>AXE automatically converts system prompts to cacheable format</li>
<li>Cache statistics are tracked and logged:<ul>
<li><span class="tt">cache_creation_input_tokens</span> - Tokens used to create cache</li>
<li><span class="tt">cache_read_input_tokens</span> - Tokens read from cache</li>
<li>Cache hit rate and savings percentage</li>
</ul>
</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md251"></a>
Example Output</h3>
<div class="fragment"><div class="line">Cache created: 2000 tokens</div>
<div class="line">Cache hit: 1800 tokens read (90.0% of input)</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md252"></a>
2. Extended Thinking</h2>
<p>Extended thinking gives Claude enhanced reasoning capabilities for complex tasks, with step-by-step thought process.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md253"></a>
Configuration</h3>
<p>Extended thinking is configured per model in <span class="tt">models.yaml</span>:</p>
<div class="fragment"><div class="line">models:</div>
<div class="line">  claude-opus-4-5-20251101:</div>
<div class="line">    extended_thinking:</div>
<div class="line">      enabled: true</div>
<div class="line">      budget_tokens: 32000     # Maximum tokens for reasoning</div>
<div class="line">  </div>
<div class="line">  claude-sonnet-4-5-20250929:</div>
<div class="line">    extended_thinking:</div>
<div class="line">      enabled: true</div>
<div class="line">      budget_tokens: 16000</div>
<div class="line">  </div>
<div class="line">  claude-haiku-4-5-20251001:</div>
<div class="line">    extended_thinking:</div>
<div class="line">      enabled: true</div>
<div class="line">      budget_tokens: 10000</div>
</div><!-- fragment --><h3 class="doxsection"><a class="anchor" id="autotoc_md254"></a>
Supported Models</h3>
<ul>
<li>Claude Opus 4.5, 4.1, 4.0 (budget: 24k-32k tokens)</li>
<li>Claude Sonnet 4.5, 4.0 (budget: 16k tokens)</li>
<li>Claude Haiku 4.5 (budget: 10k tokens)</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md255"></a>
How It Works</h3>
<ul>
<li>Claude creates internal <span class="tt">thinking</span> blocks before responding</li>
<li>Thinking is transparent (you can see the reasoning)</li>
<li>Thinking blocks include cryptographic signatures for verification</li>
<li>Claude incorporates insights from reasoning into final response</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md256"></a>
Example</h3>
<div class="fragment"><div class="line"><span class="comment"># Extended thinking is automatically enabled for supported models</span></div>
<div class="line">response = agent_manager.call_agent(<span class="stringliteral">&#39;coder&#39;</span>, <span class="stringliteral">&#39;Write optimized algorithm...&#39;</span>)</div>
<div class="line"><span class="comment"># Claude will think through the problem step-by-step internally</span></div>
<div class="line"><span class="comment"># Then provide the optimized solution</span></div>
</div><!-- fragment --><p>Console output: </p><div class="fragment"><div class="line">Extended thinking enabled with budget: 32000 tokens</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md257"></a>
3. Token Counting</h2>
<p>Get precise token counts from Anthropic's API before sending large messages.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md258"></a>
Configuration</h3>
<div class="fragment"><div class="line">anthropic:</div>
<div class="line">  token_counting:</div>
<div class="line">    enabled: true</div>
<div class="line">    threshold_estimated_tokens: 10000   # Use precise counting above this</div>
</div><!-- fragment --><h3 class="doxsection"><a class="anchor" id="autotoc_md259"></a>
How It Works</h3>
<ol type="1">
<li>AXE estimates tokens using <span class="tt">char_count / 4</span> heuristic</li>
<li>If estimate &gt; 10,000 tokens, calls Anthropic's <span class="tt">/v1/messages/count_tokens</span> endpoint</li>
<li>Uses precise count for optimization decisions</li>
<li>Non-Anthropic providers continue using estimation</li>
</ol>
<h3 class="doxsection"><a class="anchor" id="autotoc_md260"></a>
API Usage</h3>
<div class="fragment"><div class="line"><span class="comment"># Automatic - happens internally in agent_manager</span></div>
<div class="line">agent_manager.call_agent(<span class="stringliteral">&#39;coder&#39;</span>, large_prompt)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Manual - for custom use cases</span></div>
<div class="line">token_count = agent_manager.count_tokens_anthropic(</div>
<div class="line">    model=<span class="stringliteral">&#39;claude-opus-4-5-20251101&#39;</span>,</div>
<div class="line">    messages=[{<span class="stringliteral">&#39;role&#39;</span>: <span class="stringliteral">&#39;user&#39;</span>, <span class="stringliteral">&#39;content&#39;</span>: <span class="stringliteral">&#39;Your prompt here&#39;</span>}],</div>
<div class="line">    system=<span class="stringliteral">&#39;System prompt&#39;</span>,</div>
<div class="line">    tools=[...]  <span class="comment"># Optional</span></div>
<div class="line">)</div>
</div><!-- fragment --><h3 class="doxsection"><a class="anchor" id="autotoc_md261"></a>
Benefits</h3>
<ul>
<li>Avoid rate limits by knowing exact token counts</li>
<li>Make informed model routing decisions</li>
<li>Optimize prompts to specific lengths</li>
<li>Prevent failed requests due to token limits</li>
</ul>
<h2 class="doxsection"><a class="anchor" id="autotoc_md262"></a>
4. Files API (Beta)</h2>
<p>Upload large files once, reference multiple times without re-uploading.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md263"></a>
Configuration</h3>
<div class="fragment"><div class="line">anthropic:</div>
<div class="line">  files_api:</div>
<div class="line">    enabled: false                  # Beta feature, disabled by default</div>
<div class="line">    upload_threshold_kb: 50         # Auto-upload files &gt; 50KB</div>
<div class="line">    supported_types:</div>
<div class="line">      - &quot;application/pdf&quot;</div>
<div class="line">      - &quot;text/plain&quot;</div>
<div class="line">      - &quot;image/jpeg&quot;</div>
<div class="line">      - &quot;image/png&quot;</div>
</div><!-- fragment --><h3 class="doxsection"><a class="anchor" id="autotoc_md264"></a>
How It Works</h3>
<ol type="1">
<li>Upload file: <span class="tt">file_id = files_manager.upload_file('/path/to/document.pdf')</span></li>
<li>Store <span class="tt">file_id</span> in session data</li>
<li>Reference file in messages using <span class="tt">file_id</span> instead of content</li>
<li>File persists for duration of session</li>
</ol>
<h3 class="doxsection"><a class="anchor" id="autotoc_md265"></a>
Usage</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> <a class="code hl_namespace" href="namespacecore_1_1anthropic__features.html">core.anthropic_features</a> <span class="keyword">import</span> get_files_api_manager</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Initialize manager</span></div>
<div class="line">files_manager = get_files_api_manager(client, config)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Upload file</span></div>
<div class="line">file_info = files_manager.upload_file(<span class="stringliteral">&#39;/path/to/large_document.pdf&#39;</span>)</div>
<div class="line"><span class="keywordflow">if</span> file_info:</div>
<div class="line">    file_id = file_info[<span class="stringliteral">&#39;id&#39;</span>]</div>
<div class="line">    <span class="comment"># Store file_id in session for later reference</span></div>
<div class="ttc" id="anamespacecore_1_1anthropic__features_html"><div class="ttname"><a href="namespacecore_1_1anthropic__features.html">core.anthropic_features</a></div><div class="ttdef"><b>Definition</b> anthropic_features.py:1</div></div>
</div><!-- fragment --><p><b>Note</b>: Files API implementation is a placeholder. Full support requires Anthropic SDK updates.</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md266"></a>
Token Statistics with Cache Tracking</h1>
<p>The <span class="tt">TokenStats</span> class now tracks cache performance:</p>
<div class="fragment"><div class="line"><span class="keyword">from</span> <a class="code hl_namespace" href="namespaceutils_1_1token__stats.html">utils.token_stats</a> <span class="keyword">import</span> TokenStats</div>
<div class="line"> </div>
<div class="line">stats = TokenStats()</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Standard usage tracking</span></div>
<div class="line">stats.add_usage(<span class="stringliteral">&#39;agent1&#39;</span>, <span class="stringliteral">&#39;claude-opus-4-5-20251101&#39;</span>, 1000, 500)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Usage with cache tracking</span></div>
<div class="line">stats.add_usage(<span class="stringliteral">&#39;agent1&#39;</span>, <span class="stringliteral">&#39;claude-opus-4-5-20251101&#39;</span>, 500, 300,</div>
<div class="line">                cache_creation_tokens=2000,</div>
<div class="line">                cache_read_tokens=1800)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Get statistics</span></div>
<div class="line">agent_stats = stats.get_agent_stats(<span class="stringliteral">&#39;agent1&#39;</span>)</div>
<div class="line">print(f<span class="stringliteral">&quot;Cache hits: {agent_stats[&#39;cache&#39;][&#39;hits&#39;]}&quot;</span>)</div>
<div class="line">print(f<span class="stringliteral">&quot;Cache hit rate: {agent_stats[&#39;cache&#39;][&#39;hit_rate&#39;]:.1%}&quot;</span>)</div>
<div class="line"> </div>
<div class="line">total_stats = stats.get_total_stats()</div>
<div class="line">print(f<span class="stringliteral">&quot;Total cache savings: {total_stats[&#39;cache&#39;][&#39;read&#39;]} tokens&quot;</span>)</div>
<div class="ttc" id="anamespaceutils_1_1token__stats_html"><div class="ttname"><a href="namespaceutils_1_1token__stats.html">utils.token_stats</a></div><div class="ttdef"><b>Definition</b> token_stats.py:1</div></div>
</div><!-- fragment --><h1 class="doxsection"><a class="anchor" id="autotoc_md267"></a>
Configuration Reference</h1>
<p>Complete <span class="tt">models.yaml</span> configuration:</p>
<div class="fragment"><div class="line"># Anthropic-specific configuration</div>
<div class="line">anthropic:</div>
<div class="line">  # Prompt caching - reduces costs for repetitive prompts</div>
<div class="line">  prompt_caching:</div>
<div class="line">    enabled: true</div>
<div class="line">    cache_breakpoints: [&quot;system&quot;, &quot;tools&quot;]</div>
<div class="line">    default_ttl: &quot;5m&quot;              # &quot;5m&quot; (free refresh) or &quot;1h&quot; (premium)</div>
<div class="line">  </div>
<div class="line">  # Files API - upload large files once, reference multiple times</div>
<div class="line">  files_api:</div>
<div class="line">    enabled: false                 # Beta feature, disabled by default</div>
<div class="line">    upload_threshold_kb: 50</div>
<div class="line">    supported_types: [&quot;application/pdf&quot;, &quot;text/plain&quot;, &quot;image/jpeg&quot;, &quot;image/png&quot;]</div>
<div class="line">  </div>
<div class="line">  # Token counting - use precise API counts for large prompts</div>
<div class="line">  token_counting:</div>
<div class="line">    enabled: true</div>
<div class="line">    threshold_estimated_tokens: 10000</div>
<div class="line"> </div>
<div class="line"># Per-model extended thinking configuration</div>
<div class="line">models:</div>
<div class="line">  claude-opus-4-5-20251101:</div>
<div class="line">    context_tokens: 200000</div>
<div class="line">    max_output_tokens: 64000</div>
<div class="line">    input_modes: [text, image]</div>
<div class="line">    output_modes: [text, function_calling]</div>
<div class="line">    extended_thinking:</div>
<div class="line">      enabled: true</div>
<div class="line">      budget_tokens: 32000</div>
<div class="line">  </div>
<div class="line">  claude-sonnet-4-5-20250929:</div>
<div class="line">    context_tokens: 200000</div>
<div class="line">    max_output_tokens: 64000</div>
<div class="line">    input_modes: [text, image]</div>
<div class="line">    output_modes: [text, function_calling]</div>
<div class="line">    extended_thinking:</div>
<div class="line">      enabled: true</div>
<div class="line">      budget_tokens: 16000</div>
<div class="line">  </div>
<div class="line">  claude-haiku-4-5-20251001:</div>
<div class="line">    context_tokens: 200000</div>
<div class="line">    max_output_tokens: 8000</div>
<div class="line">    input_modes: [text, image]</div>
<div class="line">    output_modes: [text, function_calling]</div>
<div class="line">    extended_thinking:</div>
<div class="line">      enabled: true</div>
<div class="line">      budget_tokens: 10000</div>
</div><!-- fragment --><h1 class="doxsection"><a class="anchor" id="autotoc_md268"></a>
Backward Compatibility</h1>
<p>All features maintain full backward compatibility:</p>
<ul>
<li><b>Non-Anthropic providers</b>: Features are skipped automatically</li>
<li><b>Token callbacks</b>: Support both standard (4 params) and enhanced (6 params with cache)</li>
<li><b>Existing code</b>: No changes required to existing code</li>
<li><b>Configuration</b>: All features are opt-in via configuration</li>
</ul>
<h1 class="doxsection"><a class="anchor" id="autotoc_md269"></a>
Performance Impact</h1>
<p>Based on integration tests:</p>
<ul>
<li><b>Prompt Caching</b>: Up to 90% token cost reduction on cached content</li>
<li><b>Extended Thinking</b>: Improved quality on complex tasks (small cost increase for thinking)</li>
<li><b>Token Counting</b>: Negligible overhead (free API, called only for large prompts)</li>
<li><b>Files API</b>: Eliminates redundant uploads for large files</li>
</ul>
<h2 class="doxsection"><a class="anchor" id="autotoc_md270"></a>
Example Workflow Savings</h2>
<div class="fragment"><div class="line">Scenario: Code analysis with large codebase context</div>
<div class="line"> </div>
<div class="line">Without caching:</div>
<div class="line">  Call 1: 15,000 input tokens → $0.225 cost</div>
<div class="line">  Call 2: 15,000 input tokens → $0.225 cost</div>
<div class="line">  Call 3: 15,000 input tokens → $0.225 cost</div>
<div class="line">  Total: 45,000 tokens → $0.675</div>
<div class="line"> </div>
<div class="line">With caching:</div>
<div class="line">  Call 1: 15,000 input tokens → $0.225 cost (cache creation)</div>
<div class="line">  Call 2: 14,000 cached + 1,000 new → $0.037 cost (90% savings)</div>
<div class="line">  Call 3: 14,000 cached + 1,000 new → $0.037 cost (90% savings)</div>
<div class="line">  Total: 18,000 billable tokens → $0.299 (56% overall savings)</div>
</div><!-- fragment --><h1 class="doxsection"><a class="anchor" id="autotoc_md271"></a>
Testing</h1>
<p>Comprehensive test coverage:</p>
<ul>
<li><b>Unit tests</b>: <span class="tt"><a class="el" href="test__anthropic__features_8py.html">tests/test_anthropic_features.py</a></span> (10 tests)</li>
<li><b>Integration tests</b>: <span class="tt"><a class="el" href="test__anthropic__integration_8py.html">tests/test_anthropic_integration.py</a></span> (8 tests)</li>
<li><b>Backward compatibility</b>: All existing tests pass</li>
</ul>
<p>Run tests: </p><div class="fragment"><div class="line">python tests/test_anthropic_features.py</div>
<div class="line">python tests/test_anthropic_integration.py</div>
<div class="line">python tests/test_models_yaml.py  # Backward compatibility</div>
</div><!-- fragment --><h1 class="doxsection"><a class="anchor" id="autotoc_md272"></a>
Troubleshooting</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md273"></a>
Caching not working</h2>
<ol type="1">
<li>Check config: <span class="tt">prompt_caching.enabled: true</span> in <span class="tt">models.yaml</span></li>
<li>Verify Anthropic API key is set</li>
<li>Ensure using streaming API (AXE does this automatically)</li>
<li>Check cache TTL hasn't expired (5 minutes default)</li>
</ol>
<h2 class="doxsection"><a class="anchor" id="autotoc_md274"></a>
Extended thinking not available</h2>
<ol type="1">
<li>Verify model supports extended thinking (Claude 4.x series only)</li>
<li>Check <span class="tt">extended_thinking.enabled: true</span> for model in <span class="tt">models.yaml</span></li>
<li>Ensure sufficient <span class="tt">budget_tokens</span> configured</li>
</ol>
<h2 class="doxsection"><a class="anchor" id="autotoc_md275"></a>
Token counting fails</h2>
<ol type="1">
<li>Check <span class="tt">token_counting.enabled: true</span></li>
<li>Verify Anthropic client initialized</li>
<li>Reduce threshold if needed (default: 10,000 tokens)</li>
</ol>
<h2 class="doxsection"><a class="anchor" id="autotoc_md276"></a>
Files API not working</h2>
<ol type="1">
<li>Feature is beta - <span class="tt">enabled: false</span> by default</li>
<li>Requires Anthropic SDK updates (placeholder implementation)</li>
<li>Check beta header: <span class="tt">anthropic-beta: files-api-2025-04-14</span></li>
</ol>
<h1 class="doxsection"><a class="anchor" id="autotoc_md277"></a>
References</h1>
<ul>
<li><b>Prompt Caching</b>: <span class="tt">/home/runner/work/AXE/AXE/claude/ocr_out/Prompt caching - Claude Docs.txt</span></li>
<li><b>Extended Thinking</b>: <span class="tt">/home/runner/work/AXE/AXE/claude/ocr_out/Building with extended thinking - Claude Docs.txt</span></li>
<li><b>Token Counting</b>: <span class="tt">/home/runner/work/AXE/AXE/claude/ocr_out/Token counting - Claude Docs.txt</span></li>
<li><b>Files API</b>: <span class="tt">/home/runner/work/AXE/AXE/claude/ocr_out/Files API - Claude Docs.txt</span></li>
</ul>
<h1 class="doxsection"><a class="anchor" id="autotoc_md278"></a>
Support</h1>
<p>For issues or questions:</p><ol type="1">
<li>Check configuration in <span class="tt">models.yaml</span></li>
<li>Review test files for usage examples</li>
<li>Check Anthropic API status and documentation</li>
<li>Verify API key and rate limits </li>
</ol>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<div id="page-nav" class="page-nav-panel">
<div id="page-nav-resize-handle"></div>
<div id="page-nav-tree">
<div id="page-nav-contents">
</div><!-- page-nav-contents -->
</div><!-- page-nav-tree -->
</div><!-- page-nav -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.15.0 </li>
  </ul>
</div>
</body>
</html>
