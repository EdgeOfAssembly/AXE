# AXE Multi-Agent Test Infrastructure

This directory contains test infrastructure for verifying the AXE multi-agent system, specifically testing the bug fixes implemented in PR #18 and #20.

## üìã Overview

The test infrastructure includes:
- **3 test scripts** for different testing scenarios
- **Mock projects** for testing when external repositories unavailable
- **Real project integration** with vector-lib C library
- **Comprehensive monitoring** and reporting
- **Complete documentation** for running and verifying tests

## üéØ Purpose

These tests verify that the following critical bug fixes work correctly:

1. **XML Tag Format Support** (PR #18)
   - `<exec>command</exec>` - Command execution
   - `<read>file</read>` - File reading
   - `<write file="path">content</write>` - File creation

2. **No Double Execution** (PR #18)
   - Commands execute exactly once
   - No duplicate file operations

3. **Spawned Agent Participation** (PR #20)
   - Dynamically spawned agents receive turns
   - Proper UUID resolution

4. **Token Error Handling** (PR #20)
   - Graceful handling of 413/token limit errors
   - Error tracking and recovery
   - Session continues with remaining agents

## üìÅ Files

### Test Scripts

| File | Purpose | Runtime | Complexity |
|------|---------|---------|------------|
| `test_axe_vectorlib.sh` | Test with real C library | ~5 min | **Recommended** |
| `run_axe_test.sh` | Quick test with mock project | ~5 min | Simple |
| `test_axe_wadextract.sh` | Full test with monitoring | ~30 min | Advanced |

### Documentation

| File | Contents |
|------|----------|
| `AXE_TEST_SUMMARY.md` | Complete test documentation and results |
| `TESTING_QUICKSTART.md` | Quick start guide for running tests |
| `TEST_INFRASTRUCTURE_README.md` | This file |

### Test Projects

| Project | Source | Description |
|---------|--------|-------------|
| vector-lib | https://github.com/EdgeOfAssembly/vector-lib | Real C library for dynamic arrays |
| mock wadextract | Generated by script | Minimal C project for testing |

## üöÄ Quick Start

### 1. Prerequisites

```bash
# Install Python dependencies
pip install gnureadline openai anthropic huggingface_hub pyyaml gitpython

# Set at least one API key
export ANTHROPIC_API_KEY="your-key"
# OR
export OPENAI_API_KEY="your-key"
# OR
export HUGGINGFACE_API_KEY="your-key"
```

### 2. Run Test (Recommended)

```bash
./test_axe_vectorlib.sh
```

### 3. Check Results

```bash
# View created files
ls -la /tmp/vectorlib_test/

# Read code review
cat /tmp/vectorlib_test/CODE_REVIEW.md

# Read test report
cat /tmp/vectorlib_test/TEST_REPORT.md

# View collaboration log
less /tmp/vectorlib_test/.collab_log.md
```

## üìä Test Scenarios

### Scenario 1: Vector-lib C Library Analysis

**Script:** `test_axe_vectorlib.sh`

**What it does:**
1. Clones vector-lib from GitHub
2. Runs AXE with claude+gpt agents
3. Agents analyze C code (vector.h, align.h, example.c)
4. Agents compile example with gcc
5. Agents run the compiled program
6. Agents create CODE_REVIEW.md and TEST_REPORT.md

**Verifies:**
- ‚úÖ File reading with `<read>` tags
- ‚úÖ Command execution with `<exec>` tags
- ‚úÖ File creation with `<write file="">` tags
- ‚úÖ Compilation and execution work
- ‚úÖ No double execution
- ‚úÖ Multi-agent collaboration

**Expected files created:**
- `/tmp/vectorlib_test/CODE_REVIEW.md`
- `/tmp/vectorlib_test/TEST_REPORT.md`
- `/tmp/vectorlib_test/example` (compiled binary)
- `/tmp/vectorlib_test/.collab_log.md`

### Scenario 2: Simple Mock Project

**Script:** `run_axe_test.sh`

**What it does:**
1. Creates simple C program (prints "Hello")
2. Creates basic Makefile
3. Runs AXE with claude+gpt agents
4. Agents compile and run program
5. Agents create README.md and TEST_REPORT.md

**Verifies:**
- ‚úÖ Basic agent functionality
- ‚úÖ File operations work
- ‚úÖ Quick verification (5 minutes)

**Expected files created:**
- `/tmp/wadextract_test/README.md`
- `/tmp/wadextract_test/TEST_REPORT.md`
- `/tmp/wadextract_test/test` (compiled binary)
- `/tmp/wadextract_test/.collab_log.md`

### Scenario 3: Full Test with Monitoring

**Script:** `test_axe_wadextract.sh`

**What it does:**
1. Attempts to clone RetroCodeMess (if available)
2. Falls back to mock project if unavailable
3. Runs background monitoring of file creation
4. Runs AXE with extended time limit
5. Generates comprehensive summary report

**Verifies:**
- ‚úÖ All features from other scenarios
- ‚úÖ Continuous monitoring
- ‚úÖ Detailed reporting
- ‚úÖ Long-running session behavior

**Expected output:**
- Test results directory with timestamp
- Complete workspace copy
- Monitoring logs
- Comprehensive summary

## ‚úÖ Success Criteria

After running a test, verify:

| Criterion | How to Check | Expected |
|-----------|--------------|----------|
| AXE started | Check script output | No crash on startup |
| Agents active | `grep "Turn:" .collab_log.md` | Multiple agent turns |
| Commands executed | `grep "<exec>" .collab_log.md` | Multiple exec tags |
| Files created | `ls *.md` | README/TEST_REPORT exist |
| Compilation worked | `ls example` or `ls test` | Binary exists |
| No double execution | Check log carefully | Commands appear once |
| No crashes | Check log end | Clean completion |

## üîç Verifying Bug Fixes

### PR #18: XML Tag Support

Look for these patterns in `.collab_log.md`:

```markdown
<exec>gcc -o example example.c</exec>
[Execution Result]: [Command executed successfully]

<read>vector.h</read>
[Read Result]: [File contents...]

<write file="CODE_REVIEW.md">
# Code Review
...
</write>
[Write Result]: File created successfully
```

‚úÖ **Pass:** Tags are parsed and executed  
‚ùå **Fail:** Tags appear but no execution results

### PR #18: No Double Execution

Each command should appear once:

```bash
# Count occurrences of a specific command
grep -c "gcc -o example" .collab_log.md
# Should be 1, not 2 or more
```

‚úÖ **Pass:** Command count = 1  
‚ùå **Fail:** Command count > 1 (duplicate execution)

### PR #20: Token Error Handling

If token errors occur:

```markdown
‚ö†Ô∏è  API Error: Token limit exceeded
[Error count: 1/3 for @agent]
[Error count: 2/3 for @agent]
[Error count: 3/3 for @agent]
[@agent put to sleep]
[Session continues with remaining agents]
```

‚úÖ **Pass:** Session continues gracefully  
‚ùå **Fail:** Session crashes on token error

### PR #20: Spawned Agents

If supervisor spawns agents:

```bash
# Check for spawned agent activity
grep "Spawned agent" .collab_log.md
grep "Turn:.*UUID" .collab_log.md
```

‚úÖ **Pass:** Spawned agents receive turns  
‚ùå **Fail:** Spawned agents never get turns

## üêõ Troubleshooting

### Issue: Connection Errors

```
‚ö†Ô∏è  API Error: Connection error
```

**Causes:**
- API endpoints blocked by firewall
- No network access to AI services
- DNS resolution failing

**Solutions:**
1. Check network connectivity: `curl -I https://api.anthropic.com`
2. Try different API provider
3. Check proxy/VPN settings
4. Run in different environment (local vs. CI)

### Issue: No Files Created

```
‚ùå CODE_REVIEW.md was NOT created
```

**Causes:**
- Agents didn't execute write commands
- File write failed
- Insufficient time

**Solutions:**
1. Check `.collab_log.md` for `<write>` tags
2. Verify workspace permissions: `ls -la /tmp/vectorlib_test/`
3. Increase time limit in script
4. Check for API errors in log

### Issue: Compilation Failed

```
ERROR: gcc command failed
```

**Causes:**
- gcc not installed
- Source files missing
- Syntax errors in code

**Solutions:**
1. Install gcc: `sudo apt-get install gcc`
2. Verify source files exist
3. Check error messages in log
4. Try compiling manually

### Issue: API Quota Exceeded

```
‚ö†Ô∏è  API Error: Rate limit exceeded
```

**Causes:**
- Too many API requests
- Account quota reached
- Rate limiting active

**Solutions:**
1. Wait and retry later
2. Use different API provider
3. Increase time between requests
4. Check account quota

## üìà Performance

Expected performance:

| Metric | Value | Notes |
|--------|-------|-------|
| Test duration | 5-30 min | Depends on script |
| Agent turns | 10-50 | Depends on time limit |
| Files created | 2-5 | Reports and binaries |
| API calls | 20-100 | Per agent, per test |
| Workspace size | <10 MB | Includes all files |

## üîê Security

**API Keys:**
- ‚ö†Ô∏è Never commit API keys to repository
- ‚úÖ Use environment variables
- ‚úÖ Keys are not logged to files
- ‚úÖ Scripts check for keys before running

**Network:**
- Scripts only connect to official AI API endpoints
- No data sent to third parties
- Collaboration logs stay local

**Workspace:**
- Uses `/tmp` directory for isolation
- Cleaned up after test (optional)
- No sensitive data stored

## üìö Documentation

For more details, see:

- **Quick Start:** `TESTING_QUICKSTART.md`
- **Full Summary:** `AXE_TEST_SUMMARY.md`
- **Bug Fixes:** `BUG_FIX_SUMMARY.md`
- **AXE README:** `README.md`
- **PR #18 Details:** GitHub PR #18
- **PR #20 Details:** GitHub PR #20

## ü§ù Contributing

To add more tests:

1. Create new test script: `test_axe_<scenario>.sh`
2. Follow existing script structure
3. Document in this README
4. Add to test suite

Test script template:

```bash
#!/bin/bash
set -e

# Check API keys
if [ -z "$ANTHROPIC_API_KEY" ]; then
    echo "ERROR: No API key"
    exit 1
fi

# Setup workspace
WORKSPACE="/tmp/mytest"
rm -rf "$WORKSPACE"
mkdir -p "$WORKSPACE"

# Prepare test files
# ...

# Run AXE
./axe.py --collab claude,gpt \
         --workspace "$WORKSPACE" \
         --time 5 \
         --task "Your task here"

# Verify results
# ...
```

## üìû Support

Need help?

1. Check documentation files
2. Review `.collab_log.md` for errors
3. Open GitHub issue with:
   - Test script used
   - Error messages
   - Environment details (OS, Python version)
   - API provider used

## üéâ Success!

If tests pass, you've verified:

‚úÖ AXE multi-agent system works correctly  
‚úÖ PR #18 XML tag fixes functional  
‚úÖ PR #20 error handling works  
‚úÖ Agents collaborate effectively  
‚úÖ File operations work  
‚úÖ Command execution reliable  

**Next:** Deploy AXE with confidence! üöÄ

---

**Version:** 1.0  
**Last Updated:** 2026-01-03  
**Tested With:** AXE after PR #18 and #20
